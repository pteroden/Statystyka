{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model liniowy\n",
    "\n",
    "### Wstęp\n",
    "\n",
    "Parametry modelu szacuje się przy użyciu [Metody Najmniejszych Kwadratów](./Metody estymacji/KMNK.ipynb). Muszą być spełnione następujące warunki:\n",
    "- istnieje zależność między zmiennymi i jest ona liniowa\n",
    "- zależność między nimi jest jest losowa a nie deterministyczna – mogą istnieć losowe odchylenia.\n",
    "\n",
    "$$ y = a_0 + a_1x_1 + a_2x_2 + ... + a_kx_k + \\epsilon $$\n",
    "\n",
    "Jeśli model ma być wiarygodny, to składnik losowy nie może nieść żadnej informacji o $Y$.\n",
    "\n",
    ">**Składnik losowy musi spełniać następujące założenia:**\n",
    ">\n",
    ">- wartość oczekiwana powinna być zero $\\mathbb{E}(\\epsilon_i) = 0 $ (jeśli jest to niespełnione, to model zawiera błąd systematyczny, co sprawia, że estymatory są obciążone).\n",
    ">- wariancja składnika losowego powinna być stała $ Var(\\epsilon_i) = \\sigma^2 = const $.\n",
    ">- składniki losowe są niezależne - kowariancja powinna być równa zero $ Var(\\epsilon_i) = \\sigma^2 = const $.\n",
    "\n",
    "Skorelowanie zmiennych objaśniających powoduje niestabilność parametrów i przy małych zmianach w danych oszacowania parametrów mogą zmienić się diametralnie. Jeśli zmienne niosą tę samą informację, to rywalizują ze sobą w modelu i wynik takiej rywalizacji zależy tylko od czynników losowych.\n",
    "\n",
    "Na wyniki estymacji mogą wpływać jednostki miary. Teoretycznie podzielenie jednej zmiennej przez 1000 nie powinno zmienić estymacji, lecz występowanie bardzo małych lub bardzo dużych wartości może wpływać na kumulowanie się błędów obliczeniowych. \n",
    "\n",
    "Wpasowując linię regresji minimalizuje się sumę kwadratów błędów.\n",
    "\n",
    "Jeśli szacowane parametry są statystycznie istotne, oznacza to że parametry nie są równe zero i istnieje zależność zmiennych objaśniających od objaśnianej.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Współliniowość\n",
    "\n",
    "Często zachodzi zjawisko przybliżonej współliniowości zmiennych objaśniających, która niesie następujące niekorzystne następstwa:\n",
    "1. Niemożliwy prawdziwy pomiar siły oddziaływania zmiennych objaśniających na zmienną objaśnianą\n",
    "2. Oceny wariancji MNK-estymatora są bardzo wysokie\n",
    "3. Wartości statystyk dla zmiennych skorelowanych są małe, co oznacza celowość ich usunięcia z modelu, zaś statystyka F całości sugeruje istotność modelu regresji jako całości. \n",
    "4. Oszacowania parametrów są wrażliwe na niewielkie zmiany liczby obserwacji.\n",
    "\n",
    "Natężenie siły tych zjawisk zależy od siły zależności między zmiennymi.\n",
    "\n",
    "W przypadku współliniowości należy rozważyć:\n",
    "* Rozszerzenie lub skrócenie próby statystycznej\n",
    "* Usunięcie zmiennych będących przyczyną współliniowości\n",
    "* Zastosowanie [analizy czynnikowej]() lub [głównych składowych]() (w celu otrzymania mniejszej liczby składników ortogonalnych). \n",
    "* Nałożenie dodatkowych warunków na parametry (np. ich suma równa jedności) w celu redukcji wariancji estymatorów. \n",
    "* Dokonać transformacji zmiennych zwiększających ich wariancję (pierwsze różnice zmiennych, tempa wzrostu, logarytmy) - w wyniku transformacji następuje zmiana modelu. \n",
    "* Zastosować metodę [estymacji grzbietowej](). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Istotność zmiennych\n",
    "\n",
    "Testy t oraz test F badają istotność zmiennych. Test F bada istotność wszystkich zmiennych naraz ($H_0: b_1 = ... = b_n = 0$). Zaś testy t rozpatrują zmienne osobno ($H_0: b_1 = 0$). Poziom istotności alfa należy traktować jako prawdopodobieństwo popełnienia błędu pierwszego rodzaju (odrzucenie prawdziwej hipotezy $H_0$).\n",
    "\n",
    "**Satystyka testowa F** jest postaci:\n",
    "\n",
    "$F = \\dfrac{(R_{unrestricted}^2 - R^2_{restricted})/q}{(1-R_{unrestricted}^2)/(n - k_{unrestricted} - 1)}$\n",
    "\n",
    "gdzie:\n",
    "\n",
    "> $R^2_{restricted}$ - $R^2$ dla modelu z restrykcją\n",
    "\n",
    "> $R^2_{unrestricted}$ - $R^2$ dla modelu bez restrykcji\n",
    "\n",
    "> $q$ - liczba restrykcji\n",
    "\n",
    "> $k_{unrestricted}$ - liczba zmiennych objaśniających w modelu bez restrekcji.\n",
    "\n",
    "Ogólna zasada mówi, że im statystyka wyższa tym lepszy model. Brak możliwości odrzucenia $H_0$ oznacza, że żadna ze zmiennych objaśniających nie jest liniowo zależna od zmiennej objaśnianej.\n",
    "\n",
    "**Testy istotności t** badają czy można uznać, że współczynnik regresji jest istotnie różny od zera i że dana zmienna $x$ faktycznie wpływa na $y$.\n",
    "\n",
    "> $ H_0: b_j = 0 $ nie ma wpływu\n",
    "\n",
    "> $ H_1: b_j \\neq 0 $ istotnie wpływa na zmienną $y$\n",
    "\n",
    "Sprawdzianem hipotezy zerowej jest statystyka:\n",
    "\n",
    "$ t_j = \\dfrac{\\hat{b}_j - b_j}{S(\\hat{b}_j)} \\qquad$ jako, że $b_j = 0 $, więc\n",
    "\n",
    "$ t_j = \\dfrac{\\hat{b}_j}{S(\\hat{b}_j)} \\sim t_{n-k-1} $\n",
    "\n",
    "Decyzja weryfikacyjna jest zazwyczaj na podstawie p-value, która do przyjęcia $H_1$ musi być poniżej założonego poziomu istotności. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostyka modelu \n",
    "\n",
    "Sprawdzamy zachowanie reszt, wiarygodność wyników ze względu na dobór próbki (obserwacje odstające, jednorodność próbki), jakość dopasowania i istotność zmiennych.\n",
    "Problemu w modelowaniu mogą wynikać z wielu powiązanych ze sobą aspektów: \n",
    "* błędy w danych, braki, złe kodowanie\n",
    "* heterogeniczność próbki – może należy modelować oddzielnie?\n",
    "* wpływ zmiennych pominiętych \n",
    "* niepoprawnej formy funkcyjnej modelu\n",
    "* dobór metody estymacji – metoda źle dobrana lub zbyt słaba na dany zestaw obserwacji. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problemy w modelach regresji liniowej (charakterystyka reszt)\n",
    "__*Normalność*__ – jest wysoce pożądane, żeby reszty miały rozkład normalny oraz były identyczne i niezależne. Normalność reszt stanowi o tym, że odpowiednie statystyki mają pożądane rozkłady, np. t-Studenta, F Snedecora. Zbadać to można przy pomocy następujących testów:\n",
    ">* test Shapiro-Wilka ($H_0$: normalność) \n",
    ">* test Jarque-Bera\n",
    ">* test Kolmogorowa-Smirnowa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Heteroskedastyczność*__ – niestałość wariancji składnika losowego. Istnienie heteroskedastyczności mówi nam o nielosowości reszt. Pomimo istnienia heterosjkedastyczności estymatory pozostają nieobciążone, zgodne i asymptotyczne, lecz nie są efektywne (istnieją takie, które mają mniejszą wariancję – przekłada się to także na prognozy). W testach hipotezą zerową $H_0$ jest stałość wariancji. Niskie p-value mówi o istnieniu heteroskedastyczności. Testy badające stałość wariancji składnika losowego:\n",
    ">* test Breuscha-Pagana\n",
    ">* test Goldfelda-Quandta\n",
    ">* test Harrisona-McCabe\n",
    ">* test White’a\n",
    "\n",
    "W celu walki z heteroskedastycznością można:\n",
    "* Zlogarytmować dane – wtedy kiedy wariancja reszt rośnie wraz ze wzrostem wartości zmiennej objaśnianej i objaśniającej\n",
    "* Zmniejszy to oddziaływanie wartości skrajnych\n",
    "* Można wykorzystać do estymacji modelu [Uogólnioną Metodę Najmniejszych Kwadratów](./Metody estymacji/UMNK.ipynb)\n",
    "* Można estymować wg innego podejścia, np. wykorzystać estymatory zgodne wobec heteroskedastyczności (HC) i autokorelacji (HAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Autokorelacja*__ – skorelowanie składników losowych, co oznacza, że występują w nich dodatkowe informacje. Konsekwencje autokorelacji to nieefektywność estymatorów i późniejszych prognoz. Dodatnia autokorelacja i dodatkowo rosnący trend $X$ może powodować przeszacowanie $R^2$ i niedoszacowanie błędów. Generalnie nie testujemy danych przekrojowych, które z definicji nie można traktować jako niezależnych od siebie (np. stopy bezrobocia w sąsiednich województwach są od siebie zależne). \n",
    "\n",
    "Istnieją trzy możliwe przyczyny:\n",
    "* Pominięte zmienne\n",
    "* Nieliniowa zależność\n",
    "* Błędy pomiary\n",
    "\n",
    "Postępowanie:\n",
    "* Dodanie opóźnień (pierwszych różnic)\n",
    "* Uogólniona Metoda Najmniejszych Kwadratów\n",
    "* Wykorzystanie odpornych macierzy kowariancji estymatorów\n",
    "\n",
    "Testy badające występowanie autokorelacji:\n",
    ">* test Durbina-Watsona\n",
    ">* test Breuscha-Godfreya ($H_0$: brak autokorelacji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ocena jakości modelu\n",
    "\n",
    "** Współczynnik determinancji $R^2$ **\n",
    "\n",
    "Wskazuje on w jakim stopniu zmiany w $Y$ są wyjaśniane zmianami w $X$. Przeciwieństwem jest *współczynnik zbieżności* $\\phi^2$, który wskazuje, jaki stopień zmiany $Y$ jest tłumaczone czynnikiem losowym - $R^2 = 1 - \\phi^2$.\n",
    "$R^2$ jest miarą dopasowania modelu oraz tego w jakim stopniu reszty modelu skupiają się wokół linii regresji. Należy pamiętać, że rozproszenie reszt, poza dopasowaniem modelu, ilustruje również wariancję próbki. Wyższe $R^2$ oznacza lepsze dopasowanie modelu, ale jego wzrost w związku z dodaniem kolejnej zmiennej, nie oznacza, że zmienna ta jest istotna i potrzebna w modelu. Można wykorzystywać $R^2$ jako narzędzie porównawcze wyłącznie w modelach z tą samą zmienną zależną $Y$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$ \\qquad TSS \\quad\\;\\;\\; = \\qquad RSS \\quad + \\qquad ESS \\qquad $$\n",
    "\n",
    "$$ \\displaystyle\\sum_{t=1}^{T} (Y_t - \\bar{Y})^2 = \\displaystyle\\sum_{t=1}^{T} (\\hat{Y}_t - \\bar{Y})^2 + \\displaystyle\\sum_{t=1}^{T} (Y_t - \\hat{Y}_t)^2 $$\n",
    "\n",
    "$$ R^2 = \\dfrac{RSS}{TSS} = 1 - \\dfrac{ESS}{TSS} =  1 - \\phi^2 $$\n",
    "\n",
    "gdzie:\n",
    "> * $TSS$ - całkowita suma kwadratów odchyleń\n",
    "> * $RSS$ - regresyjna suma kwadratów (wyjaśniana przez model)\n",
    "> * $ESS$ - resztowa suma kwadratów odchyleń (niewyjaśniona przez model)\n",
    "> * $\\bar{Y}$ - średnia arytmetyczna empirycznych wartości zmiennej objaśnianej\n",
    "> * $Y_t$ - rzeczywista wartość zmiennej $Y$ w momencie $t$\n",
    "> * $\\hat{Y}_t$ - wartość teoretyczna zmiennej objaśnianej (na podstawie modelu)\n",
    "\n",
    "Dopasowanie bezwzględne modelu rośnie wraz z liczbą zmiennych objaśniających. Wzrost $R^2$ wynika ze wzrostu $RSS$ oraz stałości $TSS$. W skrajnym przypadku model z 1 zmienną musi być gorszy niż model ze 100 zmiennymi. Jednakże wzrost liczby zmiennych prowadzi do utraty stopni swopoby, więc z tego powodu należy bardziej sprawdzać *adjusted $R^2$*. Metrykę tę uzyskuje się po podzieleniu czynników $ESS$ i $TSS$ przez odpowiadające im stopnie swobody (liczba obserwacji $N$ i liczba zmiennych objaśnianych $k$).\n",
    "\n",
    "$$ R^2_{ADJ} = 1 - \\dfrac{\\dfrac{ESS}{N-(k+1)}}{\\dfrac{TSS}{N-1}} = 1 - \\dfrac{ESS}{TSS}\\bigg(\\dfrac{N-1}{N-1-k}\\bigg)$$\n",
    "\n",
    "Co sprawia, że metryka ta nie jest już ograniczona do przedziału $[0,1]$.\n",
    "\n",
    "$$ \\hat{\\delta} = \\sqrt{\\dfrac{ESS}{N-(k+1)}}$$\n",
    "\n",
    "Standardowy błąd oceny $\\hat{\\delta}$ pokazuje o ile przeciętnie wartości empiryczne odchylają się od teoretycznych.\n",
    "\n",
    "Zmniejszanie się liczby stopni swobody sprawia, że spada współczynnik $R^2_{ADJ}$, jednakże kara spowodowana tym spadkiem nie jest wystarczająca. Z tego powodu miara ta traci na znaczeniu. Można korzystać z kryteriów informacyjnych. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Kryteria informacyjne **\n",
    "\n",
    "Ocena jakości modelu możliwa jest na podstawie testów diagnostycznych lub w uproszczonej formie $R^2$. Można korzystać też z kryteriów informacyjnych:\n",
    "* AIC – Akaike Information Criteria\n",
    "* BIC – Bayesian Information Criteria\n",
    "\n",
    "Za pomocą kryteriów informacyjnych można porównywać ze sobą modele, pamiętając że zmienna objaśniana musi być taka sama także z dokładnością co do transformacji ($y$ vs. $log(y)$ wykluczone), zaś modele mogą różnić się zmiennymi objaśniającymi.\n",
    "\n",
    "$$AIC = \\bigg(\\dfrac{RSS}{N}\\bigg)exp\\bigg(\\dfrac{2K}{N}\\bigg)$$\n",
    "\n",
    "$$BIC = \\bigg(\\dfrac{RSS}{N}\\bigg)N^{\\frac{K}{N}}$$\n",
    "\n",
    "Generalnie dąży się do wybrania modelu z najniższym kryterium informacyjnym. Na ogół model z większą liczbą zmiennych objaśniających daje dokładniejsze przewidywania, lecz jest także bardziej podatny na przeuczenie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Błąd standardowy regresji **\n",
    "\n",
    "Odchylenie standardowe reszt (Residual Standard Error) jest w tych  samych jednostkach, co zmienna zależna $y$. Błąd ten można interpretować jako \"średnią\" resztę w modelu względem średniego poziomu $y$. \n",
    "\n",
    "$$ RSE = \\sqrt{\\dfrac{\\sum{e_i^2}}{n-2}} $$\n",
    "\n",
    "Wielkość ocenia się w kontekście innych statystyk zmiennej $y$. Jeżeliu $RSE = 20$ a zakres zmiennej waha się od 400 do 1000, to błąd ten można uznać za bardzo mały w granicach 2-5%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
