{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uogólniona Metoda Najmniejszych Kwadratów\n",
    "\n",
    "Zastosowanie MNK w przypadku heteroskedastyczności prowadzi do otrzymania nieefektywnych estymatorów parametrów strukturalnych oraz obciążonych estymatorów wariancji tych parametrów. Składnik losowy jest heteroskedastyczny, gdy:\n",
    "\n",
    "$$ \\mathbb{E}(\\xi\\xi^T) = \\Phi = \\delta^2\\Omega $$\n",
    "\n",
    "\n",
    "$$ \\Phi = \\begin{bmatrix} \\delta^2_1 & 0 & \\cdots & 0 \\\\ 0 & \\delta^2_2 & \\cdots & 0 \\\\ \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\ 0 & 0 & \\cdots & \\delta^2_n \\\\ \\end{bmatrix} \\;\\; \\Omega = \\begin{bmatrix} \\omega_1 & 0 & \\cdots & 0 \\\\ 0 & \\omega_2 & \\cdots & 0 \\\\ \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\ 0 & 0 & \\cdots & \\omega_n \\\\ \\end{bmatrix} \\;\\; \\Omega^{-1} = \\begin{bmatrix} \\frac{1}{\\omega_1} & 0 & \\cdots & 0 \\\\ 0 & \\frac{1}{\\omega_2} & \\cdots & 0 \\\\ \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\ 0 & 0 & \\cdots & \\frac{1}{\\omega_n} \\\\ \\end{bmatrix} $$\n",
    "\n",
    "Jeżeli znamy postać macierzy $\\Omega$ lub jej oszacowanie $\\hat{\\Omega}$, to możemy dokonać estymacji parametrów liniowego modelu ekonometrycznego uogólnioną metodą najmniejszych kwadratów (UMNK). Wówczas wektor oszacowań parametrów modelu ma postać:\n",
    "\n",
    "$$ \\hat{\\beta} = (X^T\\Omega^{-1}X)^{-1}X^T\\Omega^{-1}y $$\n",
    "\n",
    "$$ Var(\\hat{\\beta}) = (X^TX)^{-1}X^T\\Phi X(X^TX)^{-1} $$\n",
    "\n",
    "Znając $\\Omega^{-1}$ możemy bezpośrednio zastosować UMNK, a macierz tę można interpretować jako wektor wag. Wagi są odwrotnie proporcjonalne do wariancji składnika losowego w poszczególnych okresach. \n",
    "Istnieją dwa sposoby otrzymania wektora wag:\n",
    "\n",
    "1. Dzielimy próbę na podpróby. Po estymacji KMNK otrzymujemy wektor reszt losowych. W każdej podpróbie szacujemy osobno wariancję składnika losowego $\\hat{\\sigma}^2_i$. Waga dla wszystkich obserwacji przyjmuje wartości $\\dfrac{1}{\\hat{\\sigma}^2_i}$.\n",
    "\n",
    "2. Po estymacji KMNK otrzymujemy wektor reszt losowych. Kwadrat reszty losowej traktujemy jako aproksymację wariancji dla danej obserwacji. Szacujemy równanie jego regresji względem zestawu zmiennych, które mogąs objaśnić wariancję składnika losowego. Wartości teoretyczne z tej regresji to $\\hat{\\epsilon}^2_t$ a wagi $\\dfrac{1}{\\hat{\\epsilon}^2_t}$ - w praktyce, w celu zabezpieczenia przed ujemnymi wartościami $\\hat{\\epsilon}^2_t$ szacuje się regresję dla $ln(\\hat{\\epsilon}^2_t)$ dzięki czemu $\\hat{\\epsilon}^2_t = exp(\\hat{ ln \\epsilon^2_t})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku występowania homoskedastyczności ($ \\Phi = \\sigma^2I $) powyższy wzór na wariancję parametrów upraszcza się do:\n",
    "\n",
    "$ Var(\\hat{\\beta}) = \\sigma^2(X^TX)^{-1} $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
